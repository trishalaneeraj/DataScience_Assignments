{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "\n",
    "#rename admit column as actual label by creating a new one and dropping the older one.\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)\n",
    "\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)\n",
    "\n",
    "#Use the NumPy rand.permutation function to randomize the index for the admissions Dataframe.\n",
    "shuffled_index = np.random.permutation(admissions.index)\n",
    "\n",
    "#Use the loc[] method on the admissions Dataframe to return a new Dataframe in the randomized order. Assign this Dataframe to shuffled_admissions.\n",
    "shuffled_admissions = admissions.loc[shuffled_index] #RHS is a new dataframe in the randomized order.\n",
    "\n",
    "\n",
    "#Select rows 0 to 514 (including row 514) from shuffled_admissions and assign to train.\n",
    "train = shuffled_admissions.iloc[0:515]\n",
    "test = shuffled_admissions.iloc[515:len(shuffled_admissions)]\n",
    "\n",
    "print(shuffled_admissions.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train[[\"gpa\"]], train[\"actual_label\"])\n",
    "labels = model.predict(test[[\"gpa\"]])\n",
    "test[\"predicted_label\"] = labels\n",
    "matches = test[\"predicted_label\"] == test[\"actual_label\"]\n",
    "correct_predictions = test[matches]\n",
    "accuracy = len(correct_predictions) / len(test)\n",
    "\n",
    "#Calculate the sensitivity value for the predictions on the test set and assign to sensitivity.\n",
    "#Calculate the specificity value for the predictions on the test set and assign to specificity.\n",
    "\n",
    "true_positive_filter = (test[\"predicted_label\"] == 1) & (test[\"actual_label\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_label\"] == 0) & (test[\"actual_label\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "print(sensitivity)\n",
    "\n",
    "false_positive_filter = (test[\"predicted_label\"] == 1) & (test[\"actual_label\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "true_negative_filter = (test[\"predicted_label\"] == 0) & (test[\"actual_label\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "\n",
    "specificity = (true_negatives) / (false_positives + true_negatives)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Import the relevant scikit-learn package you need to calculate the ROC curve.\n",
    "#Use the model to return predicted probabilities for the test set.\n",
    "from sklearn import metrics\n",
    "probabilities = model.predict_proba(test[[\"gpa\"]])\n",
    "\n",
    "#Use the roc_curve function to return the FPR and TPR values for different thresholds.\n",
    "#Create and display a line plot with the FPR values on the x-axis and the TPR values on the y-axis.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test[\"actual_label\"], probabilities[:,1])\n",
    "plt.plot(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note the different import style!\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Calculate the AUC score for our model on the training set and assign to auc_score.\n",
    "\n",
    "probabilities = model.predict_proba(test[[\"gpa\"]])\n",
    "\n",
    "# Means we can just use roc_auc_curve() instead of metrics.roc_auc_curve()\n",
    "auc_score = roc_auc_score(test[\"actual_label\"], probabilities[:,1])\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
