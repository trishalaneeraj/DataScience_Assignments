{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up and analyzing data on passenger survival from the Titanic. Dataset: http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       29.0000\n",
      "1        2.0000\n",
      "2       30.0000\n",
      "3       25.0000\n",
      "4        0.9167\n",
      "5       47.0000\n",
      "6       63.0000\n",
      "7       39.0000\n",
      "8       58.0000\n",
      "9       71.0000\n",
      "10      47.0000\n",
      "11      19.0000\n",
      "12          NaN\n",
      "13          NaN\n",
      "14          NaN\n",
      "15      50.0000\n",
      "16      24.0000\n",
      "17      36.0000\n",
      "18      37.0000\n",
      "19      47.0000\n",
      "20      26.0000\n",
      "21      25.0000\n",
      "22      25.0000\n",
      "23      19.0000\n",
      "24      28.0000\n",
      "25      45.0000\n",
      "26      39.0000\n",
      "27      30.0000\n",
      "28      58.0000\n",
      "29          NaN\n",
      "         ...   \n",
      "1283        NaN\n",
      "1284        NaN\n",
      "1285        NaN\n",
      "1286        NaN\n",
      "1287        NaN\n",
      "1288        NaN\n",
      "1289        NaN\n",
      "1290        NaN\n",
      "1291        NaN\n",
      "1292        NaN\n",
      "1293        NaN\n",
      "1294        NaN\n",
      "1295        NaN\n",
      "1296        NaN\n",
      "1297        NaN\n",
      "1298        NaN\n",
      "1299        NaN\n",
      "1300        NaN\n",
      "1301        NaN\n",
      "1302        NaN\n",
      "1303        NaN\n",
      "1304        NaN\n",
      "1305        NaN\n",
      "1306        NaN\n",
      "1307        NaN\n",
      "1308        NaN\n",
      "1309        NaN\n",
      "1310        NaN\n",
      "1311        NaN\n",
      "1312        NaN\n",
      "Name: age, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12       True\n",
       "13       True\n",
       "14       True\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29       True\n",
       "        ...  \n",
       "1283     True\n",
       "1284     True\n",
       "1285     True\n",
       "1286     True\n",
       "1287     True\n",
       "1288     True\n",
       "1289     True\n",
       "1290     True\n",
       "1291     True\n",
       "1292     True\n",
       "1293     True\n",
       "1294     True\n",
       "1295     True\n",
       "1296     True\n",
       "1297     True\n",
       "1298     True\n",
       "1299     True\n",
       "1300     True\n",
       "1301     True\n",
       "1302     True\n",
       "1303     True\n",
       "1304     True\n",
       "1305     True\n",
       "1306     True\n",
       "1307     True\n",
       "1308     True\n",
       "1309     True\n",
       "1310     True\n",
       "1311     True\n",
       "1312     True\n",
       "Name: age, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the as keyword assigns the import to a different name, so we can reference it more easily\n",
    "# In this case, instead of having to type pandas all the time, we can just type pd\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the survival data\n",
    "f = \"titanic.csv\"\n",
    "titanic_survival = pd.read_csv(f)\n",
    "\n",
    "# Print out the age column\n",
    "print(titanic_survival[\"age\"])\n",
    "\n",
    "# We can use the isnull function to find which values in a column are missing\n",
    "age_null = pd.isnull(titanic_survival[\"age\"])\n",
    "age_null\n",
    "# age_null is a boolean vector, and has \"True\" where age is NaN, and \"False\" where it isn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#age_null\n",
    "age_null_count = len(age_null[age_null==True])\n",
    "age_null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.19418104265403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mean_age = sum(titanic_survival[\"age\"]) / len(titanic_survival[\"age\"])\n",
    "\n",
    "# Unfortunately, mean_age is NaN.  This is because any calculations we do with a null value also result in a null value.\n",
    "# This makes sense when you think about it -- how can you add a null value to a known value?\n",
    "print(mean_age)\n",
    "\n",
    "# What we have to do instead is filter the missing values out before we compute the mean.\n",
    "age_null = pd.isnull(titanic_survival[\"age\"])\n",
    "good_ages = titanic_survival[\"age\"][age_null == False]\n",
    "correct_mean_age = sum(good_ages) / len(good_ages)\n",
    "correct_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'row.names', u'pclass', u'survived', u'name', u'age', u'embarked',\n",
       "       u'home.dest', u'room', u'ticket', u'boat', u'sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_survival.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_mean_age = titanic_survival[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "passenger_classes = [1, 2, 3]\n",
    "fares_by_class = {}\n",
    "fares_by_class = {}\n",
    "for pclass in passenger_classes:\n",
    "    pclass_rows = titanic_survival[titanic_survival[\"pclass\"] == pclass]\n",
    "#    pclass_fares = pclass_rows[\"fare\"]\n",
    "#    fare_for_class = pclass_fares.mean()\n",
    "#    fares_by_class[pclass] = fare_for_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "1st    0.599379\n",
      "2nd    0.425000\n",
      "3rd    0.192686\n",
      "Name: survived, dtype: float64\n",
      "pclass\n",
      "1st    39.667773\n",
      "2nd    28.300314\n",
      "3rd    24.519658\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PIVOT_TABLE- GOOD TOOL\n",
    "import numpy as np\n",
    "\n",
    "# Let's compute the survival change from 0-1 for people in each class\n",
    "# The closer to one, the higher the chance people in that passenger class survived\n",
    "# The \"survived\" column contains a 1 if the passenger survived, and a 0 if not\n",
    "# The pivot_table method on a pandas dataframe will let us do this\n",
    "# index specifies which column to subset data based on (in this case, we want to compute the survival percentage for each class)\n",
    "# values specifies which column to subset based on the index\n",
    "# The aggfunc specifies what to do with the subsets\n",
    "# In this case, we split survived into 3 vectors, one for each passenger class, and take the mean of each\n",
    "\n",
    "passenger_survival = titanic_survival.pivot_table(index=\"pclass\", values=\"survived\", aggfunc=np.mean)\n",
    "\n",
    "# First class passengers had a much higher survival chance\n",
    "print(passenger_survival)\n",
    "passenger_age = titanic_survival.pivot_table(index=\"pclass\", values=\"age\", aggfunc=np.mean)\n",
    "print  passenger_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "female    0.663067\n",
      "male      0.167059\n",
      "Name: survived, dtype: float64\n",
      "sex\n",
      "female    30.572702\n",
      "male      31.581410\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "passenger_survival = titanic_survival.pivot_table(index=\"sex\", values=\"survived\", aggfunc=np.mean)\n",
    "\n",
    "# First class passengers had a much higher survival chance\n",
    "print(passenger_survival)\n",
    "passenger_age = titanic_survival.pivot_table(index=\"sex\", values=\"age\", aggfunc=np.mean)\n",
    "print (passenger_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age  survived\n",
      "pclass                     \n",
      "1st     39.667773  0.599379\n",
      "2nd     28.300314  0.425000\n",
      "3rd     24.519658  0.192686\n",
      "                   age  survived\n",
      "embarked                        \n",
      "Cherbourg    35.601504  0.586207\n",
      "Queenstown   29.032258  0.311111\n",
      "Southampton  29.857271  0.399651\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This will compute the mean survival chance and the mean age for each passenger class\n",
    "passenger_survival = titanic_survival.pivot_table(index=\"pclass\", values=[\"age\", \"survived\"], aggfunc=np.mean)\n",
    "print(passenger_survival)\n",
    "\n",
    "port_stats = titanic_survival.pivot_table(index=\"embarked\", values=[\"age\", \"survived\"], aggfunc=np.mean)\n",
    "print(port_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row.names pclass  survived  \\\n",
      "0            1    1st         1   \n",
      "1            2    1st         0   \n",
      "2            3    1st         0   \n",
      "3            4    1st         0   \n",
      "4            5    1st         1   \n",
      "5            6    1st         1   \n",
      "6            7    1st         1   \n",
      "7            8    1st         0   \n",
      "8            9    1st         1   \n",
      "9           10    1st         0   \n",
      "10          11    1st         0   \n",
      "11          12    1st         1   \n",
      "15          16    1st         1   \n",
      "16          17    1st         0   \n",
      "17          18    1st         0   \n",
      "18          19    1st         1   \n",
      "19          20    1st         1   \n",
      "20          21    1st         1   \n",
      "21          22    1st         0   \n",
      "22          23    1st         1   \n",
      "23          24    1st         1   \n",
      "24          25    1st         1   \n",
      "25          26    1st         0   \n",
      "26          27    1st         1   \n",
      "27          28    1st         1   \n",
      "28          29    1st         1   \n",
      "30          31    1st         1   \n",
      "31          32    1st         1   \n",
      "33          34    1st         0   \n",
      "34          35    1st         0   \n",
      "..         ...    ...       ...   \n",
      "787        788    3rd         0   \n",
      "788        789    3rd         0   \n",
      "789        790    3rd         0   \n",
      "793        794    3rd         0   \n",
      "794        795    3rd         1   \n",
      "806        807    3rd         0   \n",
      "807        808    3rd         0   \n",
      "808        809    3rd         0   \n",
      "809        810    3rd         0   \n",
      "810        811    3rd         0   \n",
      "813        814    3rd         0   \n",
      "817        818    3rd         1   \n",
      "819        820    3rd         0   \n",
      "821        822    3rd         1   \n",
      "822        823    3rd         0   \n",
      "823        824    3rd         0   \n",
      "824        825    3rd         0   \n",
      "825        826    3rd         0   \n",
      "826        827    3rd         0   \n",
      "827        828    3rd         0   \n",
      "828        829    3rd         0   \n",
      "829        830    3rd         0   \n",
      "830        831    3rd         0   \n",
      "831        832    3rd         0   \n",
      "832        833    3rd         0   \n",
      "833        834    3rd         0   \n",
      "835        836    3rd         0   \n",
      "836        837    3rd         0   \n",
      "837        838    3rd         0   \n",
      "838        839    3rd         0   \n",
      "\n",
      "                                                 name      age     embarked  \\\n",
      "0                        Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
      "1                         Allison, Miss Helen Loraine   2.0000  Southampton   \n",
      "2                 Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
      "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
      "4                       Allison, Master Hudson Trevor   0.9167  Southampton   \n",
      "5                                  Anderson, Mr Harry  47.0000  Southampton   \n",
      "6                    Andrews, Miss Kornelia Theodosia  63.0000  Southampton   \n",
      "7                              Andrews, Mr Thomas, jr  39.0000  Southampton   \n",
      "8        Appleton, Mrs Edward Dale (Charlotte Lamson)  58.0000  Southampton   \n",
      "9                              Artagaveytia, Mr Ramon  71.0000    Cherbourg   \n",
      "10                          Astor, Colonel John Jacob  47.0000    Cherbourg   \n",
      "11   Astor, Mrs John Jacob (Madeleine Talmadge Force)  19.0000    Cherbourg   \n",
      "15     Baxter, Mrs James (Helene DeLaudeniere Chaput)  50.0000    Cherbourg   \n",
      "16                            Baxter, Mr Quigg Edmond  24.0000    Cherbourg   \n",
      "17                                Beattie, Mr Thomson  36.0000    Cherbourg   \n",
      "18                       Beckwith, Mr Richard Leonard  37.0000  Southampton   \n",
      "19    Beckwith, Mrs Richard Leonard (Sallie Monypeny)  47.0000  Southampton   \n",
      "20                               Behr, Mr Karl Howell  26.0000    Cherbourg   \n",
      "21                                 Birnbaum, Mr Jakob  25.0000    Cherbourg   \n",
      "22                            Bishop, Mr Dickinson H.  25.0000    Cherbourg   \n",
      "23            Bishop, Mrs Dickinson H. (Helen Walton)  19.0000    Cherbourg   \n",
      "24            Bjornstrm-Steffansson, Mr Mauritz Hakan  28.0000  Southampton   \n",
      "25                        Blackwell, Mr Stephen Weart  45.0000  Southampton   \n",
      "26                                    Blank, Mr Henry  39.0000    Cherbourg   \n",
      "27                             Bonnell, Miss Caroline  30.0000  Southampton   \n",
      "28                            Bonnell, Miss Elizabeth  58.0000  Southampton   \n",
      "30                            Bowen, Miss Grace Scott  45.0000    Cherbourg   \n",
      "31                         Bowerman, Miss Elsie Edith  22.0000  Southampton   \n",
      "33                             Brady, Mr John Bertram  41.0000  Southampton   \n",
      "34                                  Brandeis, Mr Emil  48.0000    Cherbourg   \n",
      "..                                                ...      ...          ...   \n",
      "787                     Edvardsson, Mr Gustaf Hjalmar  18.0000  Southampton   \n",
      "788                             Eklund, Mr Hans Linus  16.0000  Southampton   \n",
      "789                                 Ekstrom, Mr Johan  45.0000  Southampton   \n",
      "793                                 Elsbury, Mr James  47.0000  Southampton   \n",
      "794                      Emanuel, Miss Virginia Ethel   5.0000  Southampton   \n",
      "806                       Ford, Miss Doolina Margaret  21.0000  Southampton   \n",
      "807                            Ford, Mr Edward Watson  18.0000  Southampton   \n",
      "808                                 Ford, Miss Maggie   9.0000  Southampton   \n",
      "809                   Ford, Mrs Edward (Margaret Ann)  48.0000  Southampton   \n",
      "810                              Ford, Mr Neil Watson  16.0000  Southampton   \n",
      "813                              Gallagher, Mr Martin  25.0000   Queenstown   \n",
      "817                               Gilnagh, Miss Katie  16.0000   Queenstown   \n",
      "819                          Goldsmith, Mr Frank John  33.0000  Southampton   \n",
      "821              Goldsmith, Master Frank John William   9.0000  Southampton   \n",
      "822                              Goldsmith, Mr Nathan  41.0000  Southampton   \n",
      "823                    Goncalves, Mr Manuel Estanslas  38.0000  Southampton   \n",
      "824                             Goodwin, Mr Frederick  40.0000  Southampton   \n",
      "825                  Goodwin, Mrs Frederick (Augusta)  43.0000  Southampton   \n",
      "826                            Goodwin, Mr Charles E.  14.0000  Southampton   \n",
      "827                          Goodwin, Miss Lillian A.  16.0000  Southampton   \n",
      "828                         Goodwin, Master Harold V.   9.0000  Southampton   \n",
      "829                           Goodwin, Miss Jessie A.  10.0000  Southampton   \n",
      "830                         Goodwin, Master Sidney L.   6.0000  Southampton   \n",
      "831                        Goodwin, Master William F.  11.0000  Southampton   \n",
      "832                                  Green, Mr George  40.0000  Southampton   \n",
      "833                   Gronnestad, Mr Daniel Danielsen  32.0000  Southampton   \n",
      "835                      Gustafsson, Mr Alfred Ossian  20.0000  Southampton   \n",
      "836                     Gustafsson, Mr Anders Vilhelm  37.0000  Southampton   \n",
      "837                       Gustafsson, Mr Johan Birger  28.0000  Southampton   \n",
      "838                        Gustafsson, Mr Karl Gideon  19.0000  Southampton   \n",
      "\n",
      "                                     home.dest     room             ticket  \\\n",
      "0                                 St Louis, MO      B-5         24160 L221   \n",
      "1              Montreal, PQ / Chesterville, ON      C26                NaN   \n",
      "2              Montreal, PQ / Chesterville, ON      C26                NaN   \n",
      "3              Montreal, PQ / Chesterville, ON      C26                NaN   \n",
      "4              Montreal, PQ / Chesterville, ON      C22                NaN   \n",
      "5                                 New York, NY     E-12                NaN   \n",
      "6                                   Hudson, NY      D-7          13502 L77   \n",
      "7                                  Belfast, NI     A-36                NaN   \n",
      "8                          Bayside, Queens, NY    C-101                NaN   \n",
      "9                          Montevideo, Uruguay      NaN                NaN   \n",
      "10                                New York, NY      NaN  17754 L224 10s 6d   \n",
      "11                                New York, NY      NaN  17754 L224 10s 6d   \n",
      "15                                Montreal, PQ  B-58/60                NaN   \n",
      "16                                Montreal, PQ  B-58/60                NaN   \n",
      "17                                Winnipeg, MN      C-6                NaN   \n",
      "18                                New York, NY     D-35                NaN   \n",
      "19                                New York, NY     D-35                NaN   \n",
      "20                                New York, NY    C-148                NaN   \n",
      "21                           San Francisco, CA      NaN                NaN   \n",
      "22                                Dowagiac, MI     B-49                NaN   \n",
      "23                                Dowagiac, MI     B-49                NaN   \n",
      "24          Stockholm, Sweden / Washington, DC      NaN                      \n",
      "25                                 Trenton, NJ      NaN                NaN   \n",
      "26                              Glen Ridge, NJ     A-31                NaN   \n",
      "27                              Youngstown, OH      C-7                NaN   \n",
      "28           Birkdale, England Cleveland, Ohio    C-103                NaN   \n",
      "30                             Cooperstown, NY      NaN                NaN   \n",
      "31            St Leonards-on-Sea, England Ohio      NaN                NaN   \n",
      "33                                 Pomeroy, WA      NaN                NaN   \n",
      "34                                   Omaha, NE      NaN   17591 L50 9s 11d   \n",
      "..                                         ...      ...                ...   \n",
      "787                   Tofta, Sweden Joliet, IL      NaN                NaN   \n",
      "788        Karberg, Sweden Jerome Junction, AZ      NaN                NaN   \n",
      "789                          Effington Rut, SD      NaN                NaN   \n",
      "793                              Illinois, USA      NaN                NaN   \n",
      "794                               New York, NY      NaN                NaN   \n",
      "806  Rotherfield, Sussex, England Essex Co, MA      NaN                NaN   \n",
      "807  Rotherfield, Sussex, England Essex Co, MA      NaN                NaN   \n",
      "808  Rotherfield, Sussex, England Essex Co, MA      NaN                NaN   \n",
      "809  Rotherfield, Sussex, England Essex Co, MA      NaN                NaN   \n",
      "810  Rotherfield, Sussex, England Essex Co, MA      NaN                NaN   \n",
      "813                               New York, NY      NaN                NaN   \n",
      "817          Co Longford, Ireland New York, NY      NaN                NaN   \n",
      "819          Strood, Kent, England Detroit, MI      NaN                NaN   \n",
      "821          Strood, Kent, England Detroit, MI      NaN                NaN   \n",
      "822                           Philadelphia, PA      NaN                NaN   \n",
      "823                                   Portugal      NaN                NaN   \n",
      "824       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "825       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "826       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "827       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "828       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "829       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "830       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "831       Wiltshire, England Niagara Falls, NY      NaN                NaN   \n",
      "832                   Dorking, Surrey, England      NaN                NaN   \n",
      "833              Foresvik, Norway Portland, ND      NaN                NaN   \n",
      "835                      Waukegan, Chicago, IL      NaN                NaN   \n",
      "836        Ruotsinphytaa, Finland New York, NY      NaN                NaN   \n",
      "837        Ruotsinphytaa, Finland New York, NY      NaN                NaN   \n",
      "838                 Myren, Sweden New York, NY      NaN                NaN   \n",
      "\n",
      "      boat     sex  \n",
      "0        2  female  \n",
      "1      NaN  female  \n",
      "2    (135)    male  \n",
      "3      NaN  female  \n",
      "4       11    male  \n",
      "5        3    male  \n",
      "6       10  female  \n",
      "7      NaN    male  \n",
      "8        2  female  \n",
      "9     (22)    male  \n",
      "10   (124)    male  \n",
      "11       4  female  \n",
      "15       6  female  \n",
      "16     NaN    male  \n",
      "17     NaN    male  \n",
      "18       5    male  \n",
      "19       5  female  \n",
      "20       5    male  \n",
      "21   (148)    male  \n",
      "22       7    male  \n",
      "23       7  female  \n",
      "24       D    male  \n",
      "25   (241)    male  \n",
      "26       7    male  \n",
      "27       8  female  \n",
      "28       8  female  \n",
      "30       4  female  \n",
      "31       6  female  \n",
      "33     NaN    male  \n",
      "34   (208)    male  \n",
      "..     ...     ...  \n",
      "787    NaN    male  \n",
      "788    NaN    male  \n",
      "789    NaN    male  \n",
      "793    NaN    male  \n",
      "794     13  female  \n",
      "806    NaN  female  \n",
      "807    NaN    male  \n",
      "808    NaN  female  \n",
      "809    NaN  female  \n",
      "810    NaN    male  \n",
      "813    NaN    male  \n",
      "817    NaN  female  \n",
      "819    NaN    male  \n",
      "821      C    male  \n",
      "822    NaN    male  \n",
      "823    NaN    male  \n",
      "824    NaN    male  \n",
      "825    NaN  female  \n",
      "826    NaN    male  \n",
      "827    NaN  female  \n",
      "828    NaN    male  \n",
      "829    NaN  female  \n",
      "830    NaN    male  \n",
      "831    NaN    male  \n",
      "832    NaN    male  \n",
      "833    NaN    male  \n",
      "835    NaN    male  \n",
      "836    NaN    male  \n",
      "837    NaN    male  \n",
      "838    NaN    male  \n",
      "\n",
      "[600 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop all rows that have missing values\n",
    "new_titanic_survival = titanic_survival.dropna()\n",
    "\n",
    "# It looks like we have an empty dataframe now.\n",
    "# This is because every row has at least one missing value.\n",
    "#print(new_titanic_survival)\n",
    "\n",
    "# We can also use the axis argument to drop columns that have missing values\n",
    "new_titanic_survival = titanic_survival.dropna(axis=1)\n",
    "#print(new_titanic_survival)\n",
    "\n",
    "# We can use the subset argument to only drop rows if certain columns have missing values.\n",
    "# This drops all rows where \"age\" or \"sex\" is missing.\n",
    "new_titanic_survival = titanic_survival.dropna(subset=[\"age\", \"home.dest\"])\n",
    "print(new_titanic_survival)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row.names pclass  survived  \\\n",
      "0          1    1st         1   \n",
      "1          2    1st         0   \n",
      "2          3    1st         0   \n",
      "3          4    1st         0   \n",
      "4          5    1st         1   \n",
      "\n",
      "                                              name      age     embarked  \\\n",
      "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
      "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
      "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
      "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
      "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
      "\n",
      "                         home.dest room      ticket   boat     sex  \n",
      "0                     St Louis, MO  B-5  24160 L221      2  female  \n",
      "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
      "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n",
      "row.names                                                  4\n",
      "pclass                                                   1st\n",
      "survived                                                   0\n",
      "name         Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)\n",
      "age                                                       25\n",
      "embarked                                         Southampton\n",
      "home.dest                    Montreal, PQ / Chesterville, ON\n",
      "room                                                     C26\n",
      "ticket                                                   NaN\n",
      "boat                                                     NaN\n",
      "sex                                                   female\n",
      "Name: 3, dtype: object\n",
      "row.names                                                  4\n",
      "pclass                                                   1st\n",
      "survived                                                   0\n",
      "name         Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)\n",
      "age                                                       25\n",
      "embarked                                         Southampton\n",
      "home.dest                    Montreal, PQ / Chesterville, ON\n",
      "room                                                     C26\n",
      "ticket                                                   NaN\n",
      "boat                                                     NaN\n",
      "sex                                                   female\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# See the numbers to the left of each row?\n",
    "# Those are row indexes.\n",
    "# Since the data has so many columns, it is split into multiple lines, but there are only 5 rows.\n",
    "print(titanic_survival.iloc[:5,:])\n",
    "\n",
    "\n",
    "#new_titanic_survival = titanic_survival.dropna(subset=[\"body\"])\n",
    "# Now let's print out the first 5 rows in new_titanic_survival\n",
    "# The row indexes here aren't the same as in titanic_survival\n",
    "# This is because we modified the titanic_survival dataframe to generate new_titanic_survival\n",
    "# The row indexes you see here are the rows from titanic_survival that made it through the dropna method (didn't have missing values in the \"body\" column)\n",
    "# They retain their original numbering, though\n",
    "#print(new_titanic_survival.iloc[:5,:])\n",
    "\n",
    "# We've been using the .iloc method to address rows and columns\n",
    "# .iloc works by position (row/column number)\n",
    "\n",
    "# This code prints the fourth row in the data\n",
    "print(new_titanic_survival.iloc[3,:])\n",
    "\n",
    "# Using .loc instead addresses rows and columns by index, not position\n",
    "# This actually prints the first row, because it has index 3\n",
    "print(new_titanic_survival.loc[3,:])\n",
    "row_index_25 = new_titanic_survival.loc[25,:]\n",
    "row_position_fifth = new_titanic_survival.iloc[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_titanic_survival = titanic_survival.dropna(subset=[\"body\"])\n",
    "\n",
    "# This prints the value in the first column of the first row\n",
    "#print(new_titanic_survival.iloc[0,0])\n",
    "\n",
    "# This prints the exact same value -- it prints the value at row index 3 and column \"pclass\"\n",
    "# This happens to also be at row 0, index 0\n",
    "#print(new_titanic_survival.loc[3,\"pclass\"])\n",
    "#row_1100_age = new_titanic_survival.loc[1100, \"age\"]\n",
    "row_25_survived = new_titanic_survival.loc[25, \"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_titanic_survival = titanic_survival.dropna(subset=[\"age\", \"boat\"])\n",
    "titanic_reindexed = new_titanic_survival.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".apply()\n",
    "By default, .apply() will iterate through each column in a dataframe, and perform a function on it.\n",
    "The column will be passed into the function.\n",
    "The result from the function will be combined with all of the other results, and placed into a new series.\n",
    "The function results will have the same position as the column they were generated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.names    1313\n",
      "pclass       1313\n",
      "survived     1313\n",
      "name         1313\n",
      "age           633\n",
      "embarked      821\n",
      "home.dest     754\n",
      "room           77\n",
      "ticket         69\n",
      "boat          347\n",
      "sex          1313\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's look at a simple example.\n",
    "# This function counts the number of null values in a series\n",
    "def null_count(column):\n",
    "    # Make a vector that contains True if null, False if not.\n",
    "    column_null = pd.isnull(column)\n",
    "    # Create a new vector with only values where the series is null.\n",
    "    null = column[column_null == False]\n",
    "    # Return the count of null values.\n",
    "    return len(null)\n",
    "\n",
    "# Compute null counts for each column\n",
    "column_not_null_count = titanic_survival.apply(null_count)\n",
    "print(column_not_null_count)\n",
    "\n",
    "#opposite-of-documentation task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing in the axis argument, we can use the .apply() method to iterate over rows instead of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will check if a row is an entry for a minor (under 18), or not.\n",
    "def age_tag(row):\n",
    "    if row[\"age\"] < 18:\n",
    "        return \"minor\"\n",
    "    elif row[\"age\"]>=18:\n",
    "        return \"adult\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "#modified to create all labels\n",
    "# This is a boolean series with the same length as the number of rows in titanic_survival\n",
    "# Each entry is True if the row at the same position is a record for a minor\n",
    "# The axis of 1 specifies that it will iterate over rows, not columns\n",
    "\n",
    "age_labels = titanic_survival.apply(age_tag, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b83ed8f3190f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Another pivotal table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mage_group_survival\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_survival\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"age_labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"survived\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage_group_survival\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\tools\\pivot.pyc\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_filter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mgrouped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0magged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[0;32m   3157\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3158\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m-> 3159\u001b[1;33m                        sort=sort, group_keys=group_keys, squeeze=squeeze)\n\u001b[0m\u001b[0;32m   3160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             grouper, exclusions, obj = _get_grouper(obj, keys, axis=axis,\n\u001b[1;32m--> 388\u001b[1;33m                                                     level=level, sort=sort)\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort)\u001b[0m\n\u001b[0;32m   2146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# df.groupby('name')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m             \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2851\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2852\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2853\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Swapnil Kant Neeraj\\Anaconda\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method)\u001b[0m\n\u001b[0;32m   1570\u001b[0m         \"\"\"\n\u001b[0;32m   1571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1572\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3824)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3704)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12280)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12231)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age_labels'"
     ]
    }
   ],
   "source": [
    "#Another pivotal table\n",
    "age_group_survival = titanic_survival.pivot_table(index=\"age_labels\", values=\"survived\", aggfunc=np.mean)\n",
    "\n",
    "print(age_group_survival)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
